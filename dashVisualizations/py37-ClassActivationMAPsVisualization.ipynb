{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import Dash, dcc, html, Input, Output,State, no_update\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import random\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cam_visualizer(img_path,resnet,activation_layer_name,fully_connected_layer_name):\n",
    "    # make a model to get output before flatten\n",
    "    activation_layer = resnet.get_layer(activation_layer_name)\n",
    "\n",
    "    # create a model object\n",
    "    model = Model(inputs=resnet.input, outputs=activation_layer.output)\n",
    "\n",
    "    # get the feature map weights\n",
    "    final_dense = resnet.get_layer(fully_connected_layer_name)\n",
    "    W = final_dense.get_weights()[0]\n",
    "\n",
    "    app = JupyterDash(__name__)\n",
    "\n",
    "    server = app.server\n",
    "    app.layout = html.Div([\n",
    "            dcc.Input(\n",
    "                id=\"upload-image\", \n",
    "                type=\"text\", \n",
    "                placeholder=\"Upload Image and get heatmap\",\n",
    "                style={\n",
    "                    'width': '100%',\n",
    "                    'height': '60px',\n",
    "                    'lineHeight': '60px',\n",
    "                    'borderWidth': '1px',\n",
    "                    'borderStyle': 'dashed',\n",
    "                    'borderRadius': '5px',\n",
    "                    'textAlign': 'center',\n",
    "                    'margin': '10px'\n",
    "                },\n",
    "            ),\n",
    "#             html.Div(id='output-prediction'),\n",
    "            html.Div(id='output-prediction',children = [])\n",
    "        ])\n",
    "    \n",
    "    @app.callback(Output('output-prediction', 'children'),\n",
    "              Input('upload-image', 'value'))\n",
    "    def prediction(img_path):\n",
    "        try:\n",
    "            if img_path is None:\n",
    "                return no_update\n",
    "            img_path = img_path\n",
    "\n",
    "            # Load the image\n",
    "            img = image.load_img(img_path, target_size=(224, 224))\n",
    "            x = preprocess_input(np.expand_dims(img, 0))\n",
    "            fmaps = model.predict(x)[0] # 7 x 7 x 2048\n",
    "\n",
    "              # get predicted class\n",
    "            probs = resnet.predict(x)\n",
    "            classnames = decode_predictions(probs)[0]\n",
    "\n",
    "            classname = classnames[0][1]\n",
    "            pred = np.argmax(probs[0])\n",
    "\n",
    "            # get the 2048 weights for the relevant class\n",
    "            w = W[:, pred]\n",
    "\n",
    "            # \"dot\" w with fmaps\n",
    "            cam = fmaps.dot(w)\n",
    "\n",
    "            # upsample to 224 x 224\n",
    "            # 7 x 32 = 224\n",
    "            cam = sp.ndimage.zoom(cam, (32, 32), order=1)\n",
    "\n",
    "            fig = px.imshow(cam)\n",
    "            children_2 = [\n",
    "                html.Img(src=img),\n",
    "                dcc.Graph(figure=fig),\n",
    "                html.Div([\n",
    "                    html.P('Major classes predicted are:-'),\n",
    "\n",
    "                ]),\n",
    "                html.Div([html.P(f\"{classes}\")  for classes in classnames])\n",
    "            ]\n",
    "            return children_2\n",
    "        except:\n",
    "            return None\n",
    "    return app\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fea0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "resnet = ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=True)\n",
    "\n",
    "# view the structure of the model\n",
    "# if you want to confirm we need activation_49\n",
    "resnet.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in resnet.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c485e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"C:\\Users\\gprak\\Downloads\\DiscUdemy Courses\\bits-logo.png\"\n",
    "app = create_cam_visualizer(image_path,resnet,'conv5_block3_out','predictions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run_server(mode=\"external\",port=8035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a673eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
